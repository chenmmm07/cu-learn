# cu-learn: CUDA GEMM Optimization Journey

è®°å½•è‡ªå·±ä»é›¶å¼€å§‹å­¦ä¹  CUDA çŸ©é˜µä¹˜æ³•ä¼˜åŒ–ï¼Œé€æ­¥å®ç°æ¥è¿‘ cuBLAS çš„æ€§èƒ½ã€‚

## ğŸ¯ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®é€šè¿‡å®é™…ä»£ç æ¼”ç¤ºå¦‚ä½•ä»æœ€åŸºæœ¬çš„çŸ©é˜µä¹˜æ³•å®ç°å¼€å§‹ï¼Œé€æ­¥åº”ç”¨å„ç§ CUDA ä¼˜åŒ–æŠ€æœ¯ï¼Œæœ€ç»ˆå®ç°é«˜æ€§èƒ½ GEMM kernelã€‚

### æ€§èƒ½æå‡
å¾…è¡¥å……

## ğŸ“š ä¼˜åŒ–æ­¥éª¤

1. **[ä¼˜åŒ– 0](src/optimizations/00_naive/)**: Naive GEMM - ç†è§£åŸºç¡€å®ç°å’Œæ€§èƒ½ç“¶é¢ˆ
2. **[ä¼˜åŒ– 1](src/optimizations/01_shared_memory/)**: Shared Memory - ä¼˜åŒ–å…¨å±€å†…å­˜è®¿é—®
3. **[ä¼˜åŒ– 2](src/optimizations/02_loop_unrolling/)**: Loop Unrolling - æš´éœ²æŒ‡ä»¤çº§å¹¶è¡Œ
4. **[ä¼˜åŒ– 3](src/optimizations/03_register_blocking/)**: Register Blocking - æå‡ç®—æœ¯å¼ºåº¦

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- CUDA Toolkit 11.0+
- CMake 3.18+
- C++14 ç¼–è¯‘å™¨
- Python 3.7+ (ç”¨äºç»˜å›¾)

### å®‰è£…ä¾èµ–

```bash
# Python ä¾èµ–
pip install -r requirements.txt
```

### ç¼–è¯‘é¡¹ç›®

```bash
mkdir build && cd build
cmake ..
make -j$(nproc)
```

### è¿è¡Œç¤ºä¾‹

#### å•ç‹¬è¿è¡ŒæŸä¸ªä¼˜åŒ–ç‰ˆæœ¬

```bash
# åŸºæœ¬ç”¨æ³•
./build/opt00_naive <M> <N> <K> [warmup] [iters] [repeats]

# å‚æ•°è¯´æ˜:
#   M, N, K: çŸ©é˜µç»´åº¦ (å¿…éœ€)
#   warmup:  é¢„çƒ­æ¬¡æ•°ï¼Œä¸è®¡å…¥ç»Ÿè®¡ (é»˜è®¤: 2)
#   iters:   æ¯æ¬¡æµ‹é‡æ‰§è¡Œçš„kernelæ¬¡æ•° (é»˜è®¤: 5)
#   repeats:  é‡å¤æµ‹é‡æ¬¡æ•°ï¼Œå–ä¸­ä½æ•° (é»˜è®¤: 4)
#
# æ³¨æ„: æ€»kernelè°ƒç”¨æ¬¡æ•° = repeats Ã— (warmup + iters)
# é»˜è®¤é…ç½®ä¸‹: 4 Ã— (2 + 5) = 28 æ¬¡è°ƒç”¨
# è¿è¡Œæ—¶é—´ â‰ˆ æ€»è°ƒç”¨æ¬¡æ•° Ã— å•æ¬¡kernelæ—¶é—´
```

#### å„ç‰ˆæœ¬è¿è¡Œç¤ºä¾‹

```bash
# ä¼˜åŒ– 0: Naive
./build/opt00_naive 2048 2048 2048

# ä¼˜åŒ– 1: Shared Memory
./build/opt01_shared 2048 2048 2048

# ä¼˜åŒ– 2: Loop Unrolling
./build/opt02_unroll 2048 2048 2048

# ä¼˜åŒ– 3: Register Blocking
./build/opt03_regblock 2048 2048 2048
```

#### è¿è¡Œå®Œæ•´ benchmark
ç›®å‰benchmarkæ˜¯åŒ…å«æ‰€æœ‰ç‰ˆæœ¬çš„ï¼Œå¯ä»¥é€šè¿‡å‚æ•°æŒ‡å®šè¿è¡Œå“ªä¸ªç‰ˆæœ¬

```bash
# è¿è¡Œå®Œæ•´ benchmark (size: 256..4096, step: 256)
./build/gemm_benchmark 256 4096 256

# è‡ªå®šä¹‰å‚æ•°
./build/gemm_benchmark <start> <stop> <step> [warmup] [iters] [repeats]

# ç¤ºä¾‹
./build/gemm_benchmark 512 2048 256

```

#### ç»˜åˆ¶æ€§èƒ½æ›²çº¿

```bash
# ç”Ÿæˆ results.csv å
cd src/plot
python plot.py

# é»˜è®¤ä¼šç”Ÿæˆ:
# - time_ms.png: æ—¶é—´å¯¹æ¯”å›¾
# - gflops.png: GFLOPS å¯¹æ¯”å›¾
# - speedup_vs_cublas.png: ç›¸å¯¹ cuBLAS çš„åŠ é€Ÿæ¯”

# å¦‚éœ€åªç»˜åˆ¶ç‰¹å®šç‰ˆæœ¬ï¼Œç¼–è¾‘ plot.py ä¸­çš„ selected_methods
```
æˆ–ä½¿ç”¨ä¾¿æ·è„šæœ¬è¿è¡Œå®Œæ•´ benchmark å¹¶ç”Ÿæˆå›¾è¡¨
```bash
./examples/full_benchmark.sh 512 2048 256
```


## ğŸ“Š æ€§èƒ½åˆ†æå·¥å…·

### Nsight Compute

```bash
# åˆ†ææŸä¸ª kernel
ncu --set full ./build/opt03_regblock 2048 2048 2048

# å¯¼å‡ºæŠ¥å‘Š
ncu --export report.ncu-rep ./build/opt03_regblock 2048 2048 2048
```

### Nsight Systems

```bash
# åˆ†æç³»ç»Ÿçº§æ€§èƒ½
nsys profile --output=report.nsys-rep ./build/gemm_benchmark 256 2048 256
```


## ğŸ“– å‚è€ƒèµ„æ–™

- [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [Nsight Compute CLI Guide](https://docs.nvidia.com/nsight-compute/)
- [Optimizing Parallel Reduction in CUDA](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼


**Happy Learning!** ğŸš€
